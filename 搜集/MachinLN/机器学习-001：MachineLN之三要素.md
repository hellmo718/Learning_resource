
**开篇废话：**

机器学习解决的问题和李航老师统计学习方法所描述的统计学问题不谋而合。李老师定义为统计学习三要素：方法=模型+策略+算法。这不光是统计学习必经之路，这也是ML、DL三大关键所在，如果你这三块系统化了以后，都可以往里套。

学习机器学习必由之路：（1）模型。（2）策略。（3）算法。

那么我的理解：

**（1）模型**

模型：官方一点就是：所要学习的条件概率或决策函数；譬如一个数学问题就是你针对解决问题列的方程组，而对于统计学来说就是我们常见的：感知机、K近邻、贝叶斯、决策树、逻辑回归、SVM等，有人就会说这不都是机器学习模型啊，我可以告诉你还真是，在不同的领域叫法是有点差别的，在经济里的统计系那么就是统计模型，在cv，nlp就是ML模型，自己瞎猜的，如果不对欢迎指出；在DL中的模型就是CNN、RNN、DNN、RBM等等。

**（2）策略**

策略：就是说你这个模型想让它按照怎么样的准则去学习，然后选择你认为的最优模型。（这地方为什么加个你认为，这就是关键，因为同一个模型有人最后只能做到98%，而有人做到99%，当然track很多，data augmentation还是必要的）其实策略就是我们通常说的损失函数（loss function）、代价函数（cost function）等，主要有：0-1损失函数，平方损失函数，绝对损失函数，对数损失函数，交叉熵等，其实这一些在推荐系统中也称之为相似度（也可以称为距离）的度量方法，简单一点像基于用户的相似度，基于商品相似度等，其实就是求的距离，那么求距离的方法就多了：欧式距离、马氏距离、汉明距离、余弦距离、皮尔逊距离等，其实很多东西都是相通的。如果你理解到这里我感觉你已经入门了，“昨夜西风调碧树，独上高楼，望尽天涯路”。（我这人喜欢吹牛逼，爱吹不要紧，一定要落实，否则前功尽弃，做自己做好自己）

当然李航老师书中还提到了经验风险和结构风险，结构风险其实就是加正则化，或者惩罚项，有：L1、L2、dropout等等。

**（3）算法**

算法：通俗一点就是解决问题的方法，一提到算法大家很快想到的是：排序、贪心、最短路径、字符串匹配等等，而这里的算法是你选择的使策略最小化的方法，有最小二乘法、牛顿法（想多了解一些数学可以看看泰勒级数，有时面试会问到）、梯度下降等，同样你要选择适合你的模型的优化方法，ML和DL有很多优化方法，不要迷失了方向，适合自己的才是最好的。

**（4）总结**

当你这三块都很了解了，那么你就可以启程远航了，恭喜你到了第二境界：“衣带渐宽终不悔，为伊消得人憔悴”，惭愧的是目前鄙人还停留在“昨夜西风调碧树，独上高楼，望尽天涯路”。

——2017年最后一篇文章

![image](http://upload-images.jianshu.io/upload_images/4618424-6e7db5ede6a7778c?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

</article>

版权声明：本文为博主原创文章，未经博主允许不得转载。有问题可以加微信：lp9628(注明CSDN)。
